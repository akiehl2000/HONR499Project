---
title: "INGARCH Modeling"
author: "Adam Kiehl"
date: "2/12/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tscount) # INGARCH model implementation

# set seed for reproducibility
set.seed(499)
```

## Introduction

The univariate log-linear INGARCH(p, q) models fit here using the `tsglm` 
function in the `tscount` package are specified according to Davis, et al. and 
Liboschik, et al. like:
$$
\begin{aligned}
\{Y_t &: t \in \mathbb{N}\} \\
\boldsymbol{X_t} &= (X_{t, 1}, ..., X_{t, r})^{T} \\
F_{t} &= \{Y_{t}, \lambda_{t}, \boldsymbol{X_{t+1}} : t \in \mathbb{N}\} \\
Y_{t} | F_{t-1} &\sim Poisson(\lambda_t) \\
\nu_{t} &= log(\lambda_{t}) \\
\nu_{t} &= \beta_{0} + \sum_{j=1}^p \beta_{j} log(Y_{t-j} + 1) + 
\sum_{k=1}^q a_k \nu_{t-k} + \boldsymbol{\eta^{T}} \boldsymbol{X_t} \\
P(Y_{t} = y |F_{t-1}) &= \frac{\lambda_{t}^{y} e^{-\lambda_{t}}}{y!}, 
y = 0, 1, 2, ...
\end{aligned}
$$
Or under a negative binomial assumption like:  
$$
\begin{aligned}
\{Y_t &: t \in \mathbb{N}\} \\
\boldsymbol{X_t} &= (X_{t, 1}, ..., X_{t, r})^{T} \\
F_{t} &= \{Y_{t}, \lambda_{t}, \boldsymbol{X_{t+1}} : t \in \mathbb{N}\} \\
Y_{t} | F_{t-1} &\sim NegBinom(\lambda_t) \\
\nu_{t} &= log(\lambda_{t}, \phi_{t}) \\
\nu_{t} &= \beta_{0} + \sum_{j=1}^p \beta_{j} log(Y_{t-j} + 1) + 
\sum_{k=1}^q a_k \nu_{t-k} + \boldsymbol{\eta^{T}} \boldsymbol{X_t} \\
P(Y_{t} = y |F_{t-1}) &= \frac{\Gamma (\phi + y)}{\Gamma (y + 1) \Gamma (\phi)} 
(\frac{\phi}{\phi + \lambda_{t}})^{\phi} 
(\frac{\lambda_{t}}{\phi + \lambda_{t}})^{y}, 
y = 0, 1, 2, ...
\end{aligned}
$$
The marginal mean $\lambda_{t}$ of the assumed poisson process is transformed 
to a linear predictor $\nu_{t}$ and modelled as a linear combination of past 
observations, past conditional means, and covariates. The model is 
parameterized in a manner resembling a classical ARMA model, with the `p` 
parameter defining the extent of the autoregressive component and the `q` 
parameter defining the moving average component. 

## Setup

The binned data frame is read and feature names are defined:
```{r}
binned_df <- read.csv('../Data/binned_df.csv')

resp_names <- c('CA1.1', 'CA1.2', 'CA1.3', 'CA1.4', 'CA1.5', 'CA1.6', 'CA1.7', 
                'CA1.8', 'CA1.9', 'CA1.10', 'CA1.11', 'CA1.12', 'CA1.13', 
                'CA1.14', 'CA1.15')
pred_names <- c('CA3.1', 'CA3.2', 'CA3.3', 'CA3.4', 'CA3.5', 'CA3.6', 'CA3.7', 
                'CA3.8', 'CA3.9', 'CA3.10', 'CA3.11', 'CA3.12', 'CA3.13', 
                'CA3.14', 'CA3.15', 'CA3.16', 'CA3.17', 'CA3.18', 'CA3.19', 
                'CA3.20', 'CA3.21')
```

A function for subsetting and cleaning data frames for modeling:
```{r}
gen_df <- function(train_trials, valid_trials, pred, resp) {
  # train_trails: a vector of trials to be included in the training set
  # valid_trials: a vector of trials to be included in the validation set
  # pred: a vector of predictor variables to be included in the data sets
  # resp: a vector of response variables to be included in the data sets
  
  # generate training set
  train_df <- binned_df %>%
    filter(trial %in% as.vector(train_trials)) %>%
    select(c(all_of(resp), all_of(pred), trial)) %>%
    data.frame()
  
  # generate validation set
  valid_df <- binned_df %>%
    filter(trial %in% as.vector(valid_trials)) %>%
    select(c(all_of(pred), trial)) %>%
    data.frame()
  
  # values to compare predicted values with
  valid_pred <- binned_df %>%
    filter(trial %in% as.vector(valid_trials)) %>%
    select(all_of(resp))
  
  # select only non-zero predictor vectors
  zeros <- c()
  zeros <- c(zeros, which(colSums(train_df) == 0))
  zeros <- c(zeros, which(colSums(valid_df) == 0))
  if (length(zeros) > 0) {
    train_df <- train_df[, -zeros]
    valid_df <- valid_df[, -zeros]
  }
  
  # return data frames
  return(list('train_df' = train_df, 
              'valid_df' = valid_df, 
              'valid_pred' = valid_pred))
}
```

A function for blocked cross-validation given the response and predictor 
variables of interest, the parameters of a model specification, and an assumed 
distribution:
```{r, message=FALSE, warning=FALSE, error=FALSE}
cross_valid <- function(pred_list, resp_list, p, q, dist) {
  # pred_list: a vector of predictor variables to be included in the data sets
  # resp_list: a vector of response variables to be included in the data sets
  # p: the number of past observations to model on
  # q: the number of lags to model the conditional mean on
  # dist: the assumed distribution for the marginal time series process
  
  # define empty vector to store MSE values
  mses <- rep(NA, 8)
  
  for (i in 1:8) {
    # select trials for training and validation (PICK ONE)
    # blocking cross-validation method is progressive
    trials <- list((10 * (i - 1) + 1):(10 * i - 2), (10 * i - 1):(10 * i))
    # time series split cross-validation method is inclusive
    # trials <- list(1:(10 * i - 2), (10 * i - 1):(10 * i))
    
    # collect data frames
    dfs <- gen_df(trials[[1]], trials[[2]], pred_list, resp_list)
    train_df <- dfs[['train_df']]
    valid_df <- dfs[['valid_df']]
    # valid_df <- dfs[['valid_df']][1:100, ]
    valid_pred <- unlist(dfs[['valid_pred']])
    # valid_pred <- dfs[['valid_pred']][1:100, ]

    remove(dfs)
    
    tryCatch(
      {
        # fit INGARCH model
        model <- tsglm(as.ts(train_df[, 1]), 
                       xreg = as.matrix(train_df[, -1]), 
                       model = list(past_obs = 1:p, past_mean = q), 
                       link = 'log', 
                       distr = dist)
      }, 
      error = function(err) {
        print(paste('Model fitting error on (', p, ', ', q, '): ', err, 
                    sep = ''))
      }
    )
    
    tryCatch(
      {
        # calculate MSE from predicted values
        pred <- predict(model, n.ahead = nrow(valid_df), newxreg = valid_df)
        mse <- mean((pred[['pred']] - valid_pred)^2, na.rm = TRUE)
        
        mses[i] <- round(mse, 4)
      }, 
      error = function(err) {
        print(paste('Model evaluation error on (', p, ', ', q, '): ', err, 
                    sep = ''))
      }
      
    )
  }
  
  return(mean(mses, na.rm = TRUE))
}
```

# Variable Selection

A function for performing variable selection on the INGARCH model using a 
forward selection technique based on the effect sizes from the full model. 
```{r, message=FALSE, warning=FALSE, error=FALSE}
var_select <- function(select, start, dist) {
  # select: the maximum number of predictor variables to model on
  # start: the start time of the model tuning procedure
  # dist: the assumed distribution for the marginal time series process

  # define empty list to store best variable subsets
  predictors <<- list()
  var_select_mses <<- list()
  
  for (resp in resp_names) {
    print(paste('Beginning variable selection for:', resp))
    
    # collect training data frame
    dfs <- gen_df(1:3, 21, pred_names, resp)
    train_df <- dfs[['train_df']]
    remove(dfs)
  
    tryCatch(
      {
        # fit full model
        model <- tsglm(as.ts(train_df[, 1]), xreg = as.matrix(train_df[, -1]), 
                 model = list(past_obs = 1, past_mean = 2), 
                 link = 'log', distr = dist)
        
        # extract estimated coefficients from fitted model
        temp <- summary(model)
        est <- temp$coefficients$Estimate[-c(1:3, 25)]
        
        # save predictors with largest effect size for forward selection
        full_model_select <<- data.frame(var = pred_names, coef = est) %>% 
          arrange(desc(abs(coef))) %>%
          top_n(select, coef) %>%
          select(var) %>%
          unlist()
      },
      error = function(err) {
        print(paste('Error:', err))
      }
    )
    
    # define empty vector to store CV MSE results for forward selection
    mses <- rep(NA, select)
    
    # perform forward selection with chosen variables
    for (i in 1:length(full_model_select)) {
      print(paste('selecting top', i, 'variables...'))
      
      preds <- full_model_select[1:i]
      
      tryCatch(
        {
          # calculate model MSE with given predictor subset
          mses[i] <- cross_valid(preds, resp, 1, 2, dist)
        }, 
        error = function(err) {
          print(paste('Error:', err))
        }
      )
    }
    
    # store selected best subset 
    forward_select <- data.frame(var_inc = 1:select,
                                 mse = mses)
    predictors[[resp]] <<- full_model_select[1:forward_select$var_inc[which(
      forward_select$mse == min(forward_select$mse))]]
    var_select_mses[[resp]] <<- as.numeric(mses)
    
    print(paste('Completed after', (Sys.time() - start), 'minutes'))
  }
  
  return(predictors)
}
```

# Model Fitting

A function for tuning the INGARCH models to acceptable parameter values given 
an optimally selected predictor set: 
```{r, message=FALSE, warning=FALSE, error=FALSE}
model_tune <- function(Pmax, Qmax, predictors, start, dist) {
  # Pmax: the maximum number of past observations to model on
  # Qmax: the maximum lagged conditional mean to model on
  # predictors: a list of optimal predictor sets for each response
  # start: the start time of the model tuning procedure
  # dist: the assumed distribution for the marginal time series process

  # define empty data frame for storing tuned values
  tuned <<- data.frame(resp = resp_names, 
                      p = rep(NA, length(resp_names)),
                      q = rep(NA, length(resp_names)))
  model_tune_mses <<- list()
  
  # loop over response variables
  for (resp in resp_names) {
    print(paste('Beginning model tuning for:', resp))
    
    # define empty data frame to store MSE results
    tuning <- data.frame(p = rep(1:Pmax, each = Qmax),
                       q = rep(1:Qmax, times = Pmax),
                       mse = rep(NA, (Pmax * Qmax)))
    
    # loop over parameter values of interest
    for (p in 1:Pmax) {
      for (q in 1:Qmax) {
        print(paste('tuning with p=', p, ' & q=', q, '...', sep=''))
        
        # calculate model MSE with given parameters
        tuning$mse[which(tuning$p == p & tuning$q == q)] <- cross_valid(
          as.vector(predictors[[resp]]), resp, p, q, dist)
      }
    }
    
    # save optimal tuned model parameters
    tuned_p <- as.numeric(tuning$p[which(tuning$mse == min(tuning$mse))])
    tuned_q <- as.numeric(tuning$q[which(tuning$mse == min(tuning$mse))])
    tuned[which(tuned$resp == resp), ] <<- c(resp, tuned_p, tuned_q)
    model_tune_mses[[resp]] <<- as.numeric(tuning$mse)
    
    print(paste('Completed after', (Sys.time() - start), 'minutes'))
  }
  
  return(tuned)
}
```

A function for fitting optimal models using selected predictors and parameters:
```{r}
fitOpt <- function(predictors, tuned, dist) {
  # predictors: a list of optimal predictor sets for each response
  # tuned: a data frame of optimal model parameters for each response
  # dist: the assumed distribution for the marginal time series process
  
  test_mses <- data.frame(resp = resp_names,
                          mse = rep(NA, length(resp_names)))
  
  for (resp in resp_names) {
    dfs <- gen_df(1:60, 61:80, predictors[[resp]], resp)
    train_df <- dfs[['train_df']]
    valid_df <- dfs[['valid_df']]
    valid_pred <- dfs[['valid_pred']]
    remove(dfs)
    
    p <- tuned$p[which(tuned$resp == resp)]
    q <- tuned$q[which(tuned$resp == resp)]
    
    print(paste('Fitting optimal model for ', resp, '...', sep = ''))
    
    model <- tsglm(as.ts(train_df[, 1]),
                   xreg = as.matrix(train_df[, -1]),
                   model = list(past_obs = 1:p, past_mean = q),
                   link = 'log',
                   distr = dist)
    
    if (dist == 'poisson') {
      model %>%
        saveRDS(paste('../Models/INGARCH_Pois/model_', resp, sep = ''))
    } else {
      model %>%
        saveRDS(paste('../Models/INGARCH_NBinom/model_', resp, sep = ''))    
    }
    
    pred <- predict(model, n.ahead = nrow(valid_df), newxreg = valid_df)
    mse <- mean((pred[['pred']] - valid_pred[, resp])^2, na.rm = TRUE)
    
    test_mses$mse[which(test$resp == resp)] <- mse
  }
  
  return(test_mses)
}
```

# Poisson Models

Find optimal subset of predictors and model parameters for poisson model:
```{r, message=FALSE, warning=FALSE, error=FALSE}
dist <- 'poisson'

# execute variable selection and model tuning
start <- Sys.time()

# collect optimal predictor subsets
predictors <- var_select(10, start)
  
# find optimal model parameters
tuned <- model_tune(5, 5, predictors, start, dist)
```

Save optimized predictor subsets and parameters, and associated MSE values:
```{r}
predictors %>%
  saveRDS('../Optimize/INGARCH_Pois/predictors.RData')

tuned %>%
  saveRDS('../Optimize/INGARCH_Pois/tuned.RData')

var_select_mses %>%
  saveRDS('../Optimize/INGARCH_Pois/varSelectMSE.RData')

model_tune_mses %>%
  saveRDS('../Optimize/INGARCH_Pois/modelTuneMSE.RData')
```

Fit optimal poisson models using selected predictors and parameters:
```{r}
test_mses <- fitOpt(predictors, tuned, dist)
```

# Negative Binomial Models

Find optimal subset of predictors and model parameters for negative binomial 
model:
```{r, message=FALSE, warning=FALSE, error=FALSE}
dist <- 'nbinom'

# execute variable selection and model tuning
start <- Sys.time()

# collect optimal predictor subsets
predictors <- var_select(10, start)
  
# find optimal model parameters
tuned <- model_tune(5, 5, predictors, start, dist)
```

Save optimized predictor subsets and parameters, and associated MSE values:
```{r}
predictors %>%
  saveRDS('../Optimize/INGARCH_NBinom/predictors.RData')

tuned %>%
  saveRDS('../Optimize/INGARCH_NBinom/tuned.RData')

var_select_mses %>%
  saveRDS('../Optimize/INGARCH_NBinom/varSelectMSE.RData')

model_tune_mses %>%
  saveRDS('../Optimize/INGARCH_NBinom/modelTuneMSE.RData')
```

Fit optimal negative binomial models using selected predictors and parameters:
```{r}
test_mses <- fitOpt(predictors, tuned, dist)

test_mses %>%
  saveRDS('../Optimize/INGARCH_NBinom/test_mses.RData')
```

Collect fitted model coefficient estimates from one-to-many models into data 
frame:
```{r}
# define empty data frame to store coefficients
coefs <- data.frame(resp = resp_names,
                    b.1 = rep(NA, 15),
                    b.2 = rep(NA, 15),
                    b.3 = rep(NA, 15),
                    b.4 = rep(NA, 15),
                    b.5 = rep(NA, 15),
                    a = rep(NA, 15),
                    CA3.1 = rep(NA, 15),
                    CA3.2 = rep(NA, 15),
                    CA3.3 = rep(NA, 15),
                    CA3.4 = rep(NA, 15),
                    CA3.5 = rep(NA, 15),
                    CA3.6 = rep(NA, 15),
                    CA3.7 = rep(NA, 15),
                    CA3.8 = rep(NA, 15),
                    CA3.9 = rep(NA, 15),
                    CA3.10 = rep(NA, 15),
                    CA3.11 = rep(NA, 15),
                    CA3.12 = rep(NA, 15),
                    CA3.13 = rep(NA, 15),
                    CA3.14 = rep(NA, 15),
                    CA3.15 = rep(NA, 15),
                    CA3.16 = rep(NA, 15),
                    CA3.17 = rep(NA, 15),
                    CA3.18 = rep(NA, 15),
                    CA3.19 = rep(NA, 15),
                    CA3.20 = rep(NA, 15),
                    CA3.21 = rep(NA, 15))
coefs <- list()

# loop through response variables
for (resp in resp_names) {
  dfs <- gen_df(1:5, 6, as.vector(predictors[[resp]]), resp)
  train_df <- dfs[['train_df']]
  remove(dfs)
  
  p <- tuned$p[which(tuned$resp == resp)]
  q <- tuned$q[which(tuned$resp == resp)]

  tryCatch(
    {
      model <- tsglm(as.ts(train_df[, 1]), xreg = as.matrix(train_df[, -1]), 
               model = list(past_obs = 1:p, past_mean = q), 
               link = 'log', distr = 'poisson')
      temp <- summary(model)
      est <- temp$coefficients$Estimate[-1]
      coefs[[resp]] <- est
      print(paste('Success:', resp))
    },
    error=function(cond) {
      coefs[[resp]] <- NA
      print(paste('Error:', resp))
    }
  )
}
```

Plot coefficient estimates from MISO models:
```{r}
coefs %>%
  pivot_longer(!resp, names_to = 'pred', values_to = 'est') %>%
  ggplot() +
  geom_tile(aes(factor(pred, levels = c('beta.1', 'beta.2', 'beta.3', 'beta.4', 
                                        'beta.5', 'a.740', pred_names)),
                factor(resp, levels = resp_names), 
                fill = as.numeric(est))) +
  scale_fill_continuous() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(title='INGARCH Coefficient Estimates', 
       x='Predictor', y='Response', fill='')
```



```{r}
model_test <- readRDS('../Models/INGARCH/model_CA1.5')
plot(model_test)
```

Testing area for quick single model fitting: 
```{r}
resp <- 'CA1.1'

# collect data frames
dfs <- gen_df(1:5, 6, pred_names, resp)
train_df <- dfs[['train_df']]
valid_df <- dfs[['valid_df']]
valid_pred <- dfs[['valid_pred']]
remove(dfs)

# fit INGARCH model
start <- Sys.time()
model <- tsglm(as.ts(train_df[, 1]), 
               xreg = as.matrix(train_df[, -1]), 
               model = list(past_obs = 1:p, past_mean = q), 
               link = 'log', 
               distr = 'nbinom')
print(Sys.time() - start)

summary(model)

# calculate MSE from predicted values
pred <- predict(model, n.ahead = nrow(valid_df), newxreg = valid_df)
mean((pred[['pred']] - valid_pred[, resp])^2, na.rm = TRUE)

plot(model)
```

